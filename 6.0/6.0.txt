游戏数据提取流程 (V3版本)
==========================================
!!!!!!! 重要信息， 最新的更新方法，从https://playthebazaar-cdn.azureedge.net/thebazaar/PatchNotes.html获取patch note， 复制其中关于事件，怪物，物品，技能部分的更新，通过cursor，手动修正。！！！！！！！！！！！！


步骤1: 抓取HTML文件
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python simple_crawler.py

输出文件: 
  - debug_monsters.html
  - debug_events.html


步骤2: 提取怪物名称
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python fetch_monster_name.py

输出文件: unique_monsters.json


步骤3: 提取事件名称
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python fetch_event_name.py

输出文件: unique_events.json
这部分需要手动修正。


步骤4: 获取物品和技能详细信息（完整版）⭐
-------------------
步骤4.1: 抓取物品和技能HTML文件
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python simple_crawler_items_skills.py

输出文件:
  - debug_items.html
  - debug_skills.html

步骤4.2: 提取物品和技能名称
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python fetch_items_skills_names.py

输出文件:
  - unique_items.json
  - unique_skills.json

步骤4.3: 获取物品和技能详细信息
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python selenium_items_skills.py

功能：
  - 从 unique_items.json 和 unique_skills.json 读取名称列表
  - 对每个物品/技能访问搜索页面（https://bazaardb.gg/search?q={名称}&c=items）
  - 从页面HTML的 pageCards JSON 中提取完整信息（名称、描述、图标、尺寸、附魔等）
  - 下载所有图标并保存到 data/icon
  - 自动检测语言并保存到相应字段（name_zh/name, description_zh/description）
  - 自动计算并添加长宽比（根据卡片尺寸）
  - 增量保存（每处理完一个立即保存）
  - 自动跳过已处理的项
  - 生成错误日志

输出目录: 
  - data/Json/
    - items.json (完整的物品数据)
    - skills.json (完整的技能数据)
  - data/icon/ (所有图标)

注意：
  - 物品和技能数据支持中英文（自动检测）
  - 从搜索页面的 pageCards JSON 中提取，包含完整信息（包括附魔）
  - 图标统一保存到 data/icon 目录


步骤5: 获取怪物详细信息（V3完整版）
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python selenium_monster_v3.py

功能：
  - 从meta描述提取技能和物品名称
  - 从HTML中提取图标URL
  - 访问详情页获取描述和尺寸
  - 下载所有图标并保存到本地（格式：怪物名_卡片名.webp）
  - 自动计算并添加长宽比（根据卡片尺寸）
  - 自动补充已有数据缺失的长宽比
  - 智能覆盖机制：只覆盖有效的新数据，保留手动修正
  - 增量保存（每处理完一个怪物立即保存）
  - 自动跳过已处理的怪物
  - 生成错误日志

输出目录: monster_details_v3/
  - monsters_v3.json (完整的怪物数据)
  - icons/ (所有技能和物品图标)
  - logs/ (错误日志)

当前统计（2025-10-08）:
  - 怪物总数: 104
  - 技能总数: 155
  - 物品总数: 561
  - 图标总数: 716
  - 完整度: 100%


步骤6: 重试失败的项
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python retry_failed_items.py

功能：
  - 读取最新的错误日志
  - 重新抓取完全失败的怪物
  - 重新下载失败的图标
  - 自动更新JSON文件


步骤7: 检查数据完整性
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python check_data_completeness.py

功能：
  - 统计怪物、技能、物品数量
  - 检查缺失的图标、描述
  - 识别无技能/无物品的怪物
  - 计算数据完整度


步骤8: 手动更新缺失信息


步骤9: 获取事件详细信息（完整版）
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python selenium_event_final.py

功能：
  - 从pool数据提取选择信息（名称、URL、图标URL）
  - 从DOM中提取选择的描述
  - 下载所有选择图标并保存到本地（格式：事件名/选择名.webp）
  - 增量保存（每处理完一个事件立即保存）
  - 自动跳过已处理的事件
  - 生成详细的错误日志和统计报告

输出目录: event_details_final/
  - events_final.json (完整的事件数据)
  - icons/ (所有选择图标，按事件分目录)
  - logs/ (错误日志)

步骤10: 手动修正失败项
-------------------
根据错误日志手动处理：
  1. 下载超时的图标
  2. 补充缺失的描述
  3. 更新JSON文件中的对应字段


==========================================
完整操作流程（快速参考）
==========================================

物品和技能数据提取：
------------------
1. 运行 selenium_items_skills.py   → 获取完整物品和技能数据
   - items_details/items.json + icons/
   - skills_details/skills.json + icons/
2. 手动修正缺失的图标和描述       → 根据错误日志处理

怪物数据提取：
--------------
1. 运行 simple_crawler.py          → 获取 debug_monsters.html
2. 运行 fetch_monster_name.py      → 获取 unique_monsters.json
3. 运行 selenium_monster_v3.py     → 获取完整怪物数据（monster_details_v3/）
4. 运行 retry_failed_items.py      → 重试失败的项（可选）
5. 运行 check_data_completeness.py → 检查数据完整性
6. 手动修正缺失的图标和描述       → 根据错误日志处理

事件数据提取：
--------------
1. 从db网站截取事件列表图片，直接cursor识别生成 unique_events.json 文件。
2. 运行 selenium_event_final.py    → 获取完整事件数据（event_details_final/）
3. 手动修正缺失的图标和描述       → 根据错误日志处理

最终输出：
----------
- 物品数据: 6.0/crawlers/items_details/items.json + icons/
- 技能数据: 6.0/crawlers/skills_details/skills.json + icons/
- 怪物数据: 6.0/crawlers/monster_details_v3/monsters_v3.json + icons/
- 事件数据: 6.0/crawlers/event_details_final/events_final.json + icons/

注意事项：
----------
- 所有脚本支持增量保存，中断后可继续运行
- 错误日志位于各输出目录的 logs/ 子目录
- 手动修正后无需重新运行整个流程


==========================================
游戏更新后的安全更新流程（新增）⭐
==========================================

当游戏更新后，需要更新数据但又要保留手动修正的内容：

步骤1: 备份当前数据（必须！）
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python backup_current_data.py

功能：
  - 自动备份所有怪物和事件数据
  - 备份所有图标文件
  - 创建带时间戳的备份目录
  - 生成备份摘要报告

输出目录: backups/backup_YYYYMMDD_HHMMSS/
  - monster_details_v3/ (怪物数据备份)
  - event_details_final/ (事件数据备份)
  - unique_monsters.json (名称列表备份)
  - unique_events.json (名称列表备份)
  - backup_summary.json (备份摘要)


步骤2: 获取最新名称列表
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python simple_crawler.py
python fetch_monster_name.py
python fetch_event_name.py

手动修正: 检查并修正 unique_events.json（如需要）


步骤3: 对比找出新增项
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python compare_names.py

功能：
  - 对比新旧 unique_monsters.json
  - 对比新旧 unique_events.json
  - 找出新增的怪物和事件
  - 生成只包含新增项的列表文件

输出文件:
  - new_monsters.json (新增怪物列表)
  - new_events.json (新增事件列表)

输出示例:
  总怪物数: 110
  已有怪物: 104
  新增怪物: 6
  
  新增的怪物:
    + New Monster 1
    + New Monster 2
    ...


步骤4: 爬取新增项（自动跳过已有）
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"

# 方式A: 直接运行（推荐）
python selenium_items_skills.py   # 更新物品和技能数据（自动跳过已有）⭐
python selenium_monster_v3.py
python selenium_event_final.py

# 爬虫会自动：
#   1. 加载已有数据
#   2. 跳过已处理的项
#   3. 只处理新增项
#   4. 保留所有手动修正

说明：
  - 爬虫内置增量更新机制
  - 自动跳过已存在的怪物/事件
  - 手动修正的内容完全不会被覆盖
  - 图标文件如已存在会自动跳过下载


步骤5: 检查更新结果
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python check_data_completeness.py

检查项：
  - 新增项是否全部爬取成功
  - 图标是否下载完整
  - 数据完整性统计


步骤6: 手动处理失败项（如需要）
-------------------
根据 logs/error_log_*.json 手动处理：
  - 下载失败的图标
  - 补充缺失的描述
  - 修正错误数据


安全更新流程总结：
------------------
1. backup_current_data.py         → 备份所有数据（必须！）
2. selenium_items_skills.py        → 更新物品和技能数据（自动跳过已有）⭐
3. simple_crawler.py              → 获取最新网页
4. fetch_monster_name.py          → 提取怪物名称
5. fetch_event_name.py            → 提取事件名称
6. [手动修正 unique_events.json]  → 修正事件名称（如需要）
7. compare_names.py               → 对比找出新增项
8. selenium_monster_v3.py         → 爬取新增怪物（自动跳过已有）
9. selenium_event_final.py        → 爬取新增事件（自动跳过已有）
10. check_data_completeness.py     → 检查数据完整性
11. [手动处理失败项]              → 根据错误日志处理

优势：
------
✅ 自动备份，安全可靠
✅ 增量更新，只添加新内容
✅ 保留手动修正，不会覆盖
✅ 自动跳过已有项，效率高
✅ 完整的对比和检查机制

详细说明：
----------
参见 "安全更新指南.md" 获取完整的图文教程和问题排查


==========================================
辅助工具脚本说明
==========================================

backup_current_data.py
----------------------
功能: 自动备份所有数据
用途: 每次更新前必须运行
输出: backups/backup_YYYYMMDD_HHMMSS/

compare_names.py
----------------
功能: 对比新旧名称列表，生成新增项列表
用途: 找出游戏更新后新增的怪物和事件
输出: new_monsters.json, new_events.json

merge_data.py
-------------
功能: 智能合并临时数据到正式数据
用途: 如果需要手动合并数据时使用
注意: 通常不需要，爬虫已支持自动合并

check_data_completeness.py
--------------------------
功能: 检查数据完整性
用途: 验证数据是否完整，找出缺失项
输出: 统计报告和缺失项列表

test_extract_size.py
--------------------
功能: 测试卡片尺寸提取功能
用途: 验证能否正确从网页提取尺寸信息
说明: 测试 Ahexa 的4个物品（3种不同比例）
注意: 测试通过后，selenium_monster_v3.py 会自动使用此方法


==========================================
图标长宽比说明（新增）⭐
==========================================

长宽比（aspect_ratio）用于正确显示图标：
- 0.5 = 竖长图 (宽:高 = 1:2) - Small 卡片
- 1.0 = 正方形 (宽:高 = 1:1) - Medium 卡片
- 1.5 = 横长图 (宽:高 = 3:2) - Large 卡片

卡片尺寸 → 长宽比映射：
- Small → 0.5 (竖长)
- Medium → 1.0 (正方形)
- Large → 1.5 (横长)

数据分布：
- 技能图标: 通常为 Medium (1.0)
- 事件选择图标: 全部为 Medium (1.0) ← 不需要更新
- 物品图标: 根据卡片尺寸自动确定 (0.5/1.0/1.5)

工作原理：
1. 爬虫访问卡片详情页
2. 从HTML提取尺寸标签 (Small/Medium/Large)
3. 根据尺寸映射计算长宽比
4. 保存到JSON的 aspect_ratio 字段

使用方法：
---------
方式1: 直接运行爬虫（推荐）⭐
  python selenium_monster_v3.py
  → 自动完成所有工作：
    1. 检查并更新已有数据的长宽比
    2. 爬取新怪物（自动包含长宽比）
  
方式2: 测试验证
  python test_extract_size.py
  → 测试 Ahexa 的4个物品，验证提取功能

注意：
- 事件数据不需要更新（所有选择都是1.0）
- 下载的图标都是256x256，无法从文件获取真实比例
- 必须从网页HTML中提取卡片尺寸信息


==========================================
Bazaar_Lens 程序修复说明（2025-10-13）⭐
==========================================

最新修复内容：
--------------
1. 修复了窗口高度逐渐减少的bug
2. 修复了日志文件权限问题
3. 改进了窗口录屏兼容性
4. 添加了自动日志管理功能

修复详情：
----------

1. 窗口高度bug修复：
   - 原因：打包环境和开发环境的OCR策略不同，导致窗口大小计算错误
   - 解决：统一使用线程超时策略，分离移动和调整操作
   - 效果：信息窗口不再逐渐缩小

2. 日志文件权限修复：
   - 原因：程序试图在Program Files目录创建日志文件，权限不足
   - 解决：智能选择日志位置（用户文档目录 > 临时目录）
   - 效果：不再出现权限错误，日志正常生成

3. 录屏兼容性改进：
   - 原因：无边框窗口无法被录屏软件捕获
   - 解决：恢复标准窗口边框，保留顶层属性
   - 效果：Win+G录屏可以正常捕获信息窗口

4. 日志管理功能：
   - 自动旋转日志（最大10MB，保留3个备份）
   - 系统托盘菜单添加"清理日志文件"选项
   - 智能清理：当前日志清空，备份日志删除

安装程序改进：
--------------
1. 强制关闭运行中的程序（不询问用户）
2. 覆盖安装，保留用户配置
3. 自动处理文件锁定问题

技术细节：
----------
- OCR策略统一：开发环境和打包环境都使用线程超时
- 窗口操作分离：show/adjust（调整大小+位置）vs move（仅移动位置）
- 日志路径智能选择：Documents/Bazaar_Lens/ 或 Temp/Bazaar_Lens/
- 安装前强制终止：使用InitializeSetup()函数提前关闭程序

使用建议：
----------
1. 日志管理：通过系统托盘菜单定期清理日志
2. 录屏制作：使用OBS Studio或OpenShot等专业软件
3. 程序更新：直接运行新安装程序，会自动关闭旧版本
4. 问题排查：查看用户文档目录下的日志文件

版本信息：
----------
- 当前版本：v1.0.1
- 主要修复：窗口bug、权限问题、录屏兼容
- 安装程序：支持强制关闭、覆盖安装
