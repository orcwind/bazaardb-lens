游戏数据提取流程 (V3版本)
==========================================

步骤1: 抓取HTML文件
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python simple_crawler.py

输出文件: 
  - debug_monsters.html
  - debug_events.html


步骤2: 提取怪物名称
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python fetch_monster_name.py

输出文件: unique_monsters.json


步骤3: 提取事件名称
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python fetch_event_name.py

输出文件: unique_events.json
这部分需要手动修正。


步骤4: 获取怪物详细信息（V3完整版）
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python selenium_monster_v3.py

功能：
  - 从meta描述提取技能和物品名称
  - 从HTML中提取图标URL
  - 访问详情页获取描述
  - 下载所有图标并保存到本地（格式：怪物名_卡片名.webp）
  - 增量保存（每处理完一个怪物立即保存）
  - 自动跳过已处理的怪物
  - 生成错误日志

输出目录: monster_details_v3/
  - monsters_v3.json (完整的怪物数据)
  - icons/ (所有技能和物品图标)
  - logs/ (错误日志)

当前统计（2025-10-08）:
  - 怪物总数: 104
  - 技能总数: 155
  - 物品总数: 561
  - 图标总数: 716
  - 完整度: 100%


步骤5: 重试失败的项
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python retry_failed_items.py

功能：
  - 读取最新的错误日志
  - 重新抓取完全失败的怪物
  - 重新下载失败的图标
  - 自动更新JSON文件


步骤6: 检查数据完整性
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python check_data_completeness.py

功能：
  - 统计怪物、技能、物品数量
  - 检查缺失的图标、描述
  - 识别无技能/无物品的怪物
  - 计算数据完整度


步骤7: 手动更新缺失信息


步骤8: 获取事件详细信息（完整版）
-------------------
cd "d:\PythonProject\BazaarInfo\bazaardb-desktop\6.0\crawlers"
python selenium_event_final.py

功能：
  - 从pool数据提取选择信息（名称、URL、图标URL）
  - 从DOM中提取选择的描述
  - 下载所有选择图标并保存到本地（格式：事件名/选择名.webp）
  - 增量保存（每处理完一个事件立即保存）
  - 自动跳过已处理的事件
  - 生成详细的错误日志和统计报告

输出目录: event_details_final/
  - events_final.json (完整的事件数据)
  - icons/ (所有选择图标，按事件分目录)
  - logs/ (错误日志)

步骤9: 手动修正失败项
-------------------
根据错误日志手动处理：
  1. 下载超时的图标
  2. 补充缺失的描述
  3. 更新JSON文件中的对应字段


==========================================
完整操作流程（快速参考）
==========================================

怪物数据提取：
--------------
1. 运行 simple_crawler.py          → 获取 debug_monsters.html
2. 运行 fetch_monster_name.py      → 获取 unique_monsters.json
3. 运行 selenium_monster_v3.py     → 获取完整怪物数据（monster_details_v3/）
4. 运行 retry_failed_items.py      → 重试失败的项（可选）
5. 运行 check_data_completeness.py → 检查数据完整性
6. 手动修正缺失的图标和描述       → 根据错误日志处理

事件数据提取：
--------------
1. 运行 simple_crawler.py          → 获取 debug_events.html
2. 运行 fetch_event_name.py        → 获取 unique_events.json
3. 手动修正 unique_events.json     → 检查并修正事件名称
4. 运行 selenium_event_final.py    → 获取完整事件数据（event_details_final/）
5. 手动修正缺失的图标和描述       → 根据错误日志处理

最终输出：
----------
- 怪物数据: 6.0/crawlers/monster_details_v3/monsters_v3.json + icons/
- 事件数据: 6.0/crawlers/event_details_final/events_final.json + icons/

注意事项：
----------
- 所有脚本支持增量保存，中断后可继续运行
- 错误日志位于各输出目录的 logs/ 子目录
- 手动修正后无需重新运行整个流程