"""
Seleniumäº‹ä»¶çˆ¬è™« - å®Œæ•´ç‰ˆ
åŠŸèƒ½ï¼š
1. ä»é¡µé¢çš„ <script> æ ‡ç­¾ä¸­æå– pool æ•°æ®ï¼ˆè·å–é€‰æ‹©åç§°ã€URLã€å›¾æ ‡ï¼‰
2. ä»DOMä¸­æå–é€‰æ‹©çš„æè¿°
3. ä¸‹è½½å›¾æ ‡å¹¶ä¿å­˜åˆ°æœ¬åœ°
4. å¢é‡ä¿å­˜
"""

import json
import time
import re
import requests
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException

# é…ç½®
PROJECT_ROOT = Path(__file__).parent.parent.parent
OUTPUT_DIR = PROJECT_ROOT / 'data' / 'Json'
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
ICONS_DIR = PROJECT_ROOT / 'data' / 'icon' / 'event'
ICONS_DIR.mkdir(parents=True, exist_ok=True)
HTML_DIR = PROJECT_ROOT / 'data' / 'html' / 'event'
HTML_DIR.mkdir(parents=True, exist_ok=True)
LOGS_DIR = OUTPUT_DIR / 'logs'
LOGS_DIR.mkdir(parents=True, exist_ok=True)
EVENTS_FILE = PROJECT_ROOT / 'data' / 'Json' / 'events_only_list.json'

# å…¨å±€é”™è¯¯æ—¥å¿—
ERROR_LOG = {
    'failed_events': [],
    'missing_detail_urls': [],
    'missing_choices': [],
    'failed_choice_downloads': [],
    'failed_descriptions': [],
    'exceptions': []
}


def setup_driver():
    """è®¾ç½®Chromeé©±åŠ¨"""
    options = webdriver.ChromeOptions()
    # options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--window-size=1920,1080')
    # è®¾ç½®è¯­è¨€åå¥½ä¸ºä¸­æ–‡ï¼Œä¼˜å…ˆä¸­æ–‡ï¼Œå…¶æ¬¡è‹±æ–‡
    options.add_argument('--lang=zh-CN')
    options.add_experimental_option('prefs', {
        'intl.accept_languages': 'zh-CN,zh,en-US,en'
    })
    driver = webdriver.Chrome(options=options)
    # é€šè¿‡JavaScriptè®¾ç½®Accept-Language header
    driver.execute_cdp_cmd('Network.setUserAgentOverride', {
        "userAgent": driver.execute_script("return navigator.userAgent;"),
        "acceptLanguage": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7"
    })
    return driver


def load_event_names(file_path):
    """ä»æ–‡ä»¶ä¸­åŠ è½½äº‹ä»¶åç§°åˆ—è¡¨"""
    try:
        # æ”¯æŒ Path å¯¹è±¡å’Œå­—ç¬¦ä¸²è·¯å¾„
        if isinstance(file_path, Path):
            names = [line.strip().strip('"') for line in file_path.read_text(encoding='utf-8').splitlines() if line.strip()]
        else:
            with open(file_path, 'r', encoding='utf-8') as f:
                names = [line.strip().strip('"') for line in f if line.strip()]
        return names
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return []


def get_icon_aspect_ratio(filepath):
    """è·å–å›¾æ ‡çš„é•¿å®½æ¯”
    
    Args:
        filepath: å›¾æ ‡æ–‡ä»¶è·¯å¾„
    
    Returns:
        é•¿å®½æ¯” (width/height)ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› 1.0
    """
    try:
        from PIL import Image
        with Image.open(filepath) as img:
            width, height = img.size
            if height == 0:
                return 1.0
            aspect_ratio = width / height
            
            # å››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„æ ‡å‡†æ¯”ä¾‹ (0.5, 1.0, 1.5)
            if aspect_ratio < 0.75:
                return 0.5
            elif aspect_ratio < 1.25:
                return 1.0
            else:
                return 1.5
    except Exception as e:
        print(f"        âš  è·å–é•¿å®½æ¯”å¤±è´¥: {e}")
        return 1.0


def download_icon(icon_url, event_name, choice_name):
    """ä¸‹è½½å›¾æ ‡å¹¶è¿”å›è·¯å¾„å’Œé•¿å®½æ¯”
    
    Returns:
        (æœ¬åœ°å›¾æ ‡è·¯å¾„, é•¿å®½æ¯”) æˆ– ("", 1.0) å¦‚æœä¸‹è½½å¤±è´¥
    """
    try:
        # æ¸…ç†æ–‡ä»¶å
        safe_event_name = "".join([c for c in event_name if c.isalnum() or c in (' ', '-', '_')]).strip()
        safe_choice_name = "".join([c for c in choice_name if c.isalnum() or c in (' ', '-', '_')]).strip()
        
        # åˆ›å»ºäº‹ä»¶ç›®å½•
        event_dir = ICONS_DIR / safe_event_name
        event_dir.mkdir(parents=True, exist_ok=True)
        
        # è·å–å›¾æ ‡æ‰©å±•å
        ext = icon_url.split('.')[-1].split('?')[0]
        if not ext or len(ext) > 4:
            ext = 'webp'
        
        # ä¿å­˜è·¯å¾„
        icon_path = event_dir / f"{safe_choice_name}.{ext}"
        
        # å¦‚æœå·²å­˜åœ¨ï¼Œè·å–é•¿å®½æ¯”å¹¶è¿”å›
        if icon_path.exists():
            aspect_ratio = get_icon_aspect_ratio(icon_path)
            # è¿”å›ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
            return str(icon_path.relative_to(PROJECT_ROOT)).replace('\\', '/'), aspect_ratio
        
        # ä¸‹è½½å›¾æ ‡
        response = requests.get(icon_url, timeout=10)
        if response.status_code == 200:
            with open(icon_path, 'wb') as f:
                f.write(response.content)
            
            # è·å–é•¿å®½æ¯”
            aspect_ratio = get_icon_aspect_ratio(icon_path)
            # è¿”å›ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
            return str(icon_path.relative_to(PROJECT_ROOT)).replace('\\', '/'), aspect_ratio
        else:
            ERROR_LOG['failed_choice_downloads'].append({
                'event': event_name,
                'choice': choice_name,
                'url': icon_url,
                'status': response.status_code
            })
            return "", 1.0
    except Exception as e:
        ERROR_LOG['failed_choice_downloads'].append({
            'event': event_name,
            'choice': choice_name,
            'url': icon_url,
            'error': str(e)
        })
        return "", 1.0


def smart_merge_choice_data(existing_choice, new_choice):
    """æ™ºèƒ½åˆå¹¶äº‹ä»¶é€‰æ‹©æ•°æ®
    
    è§„åˆ™ï¼š
    1. å¦‚æœæ–°æ•°æ®ä¸ºç©ºæˆ–æ— æ•ˆï¼Œä¿ç•™åŸæœ‰æ•°æ®
    2. å¦‚æœæ–°æ•°æ®æœ‰æ•ˆï¼Œä½¿ç”¨æ–°æ•°æ®è¦†ç›–
    3. å›¾æ ‡è·¯å¾„ï¼šå¦‚æœæ–°å›¾æ ‡ä¸‹è½½æˆåŠŸï¼Œä½¿ç”¨æ–°è·¯å¾„ï¼›å¦åˆ™ä¿ç•™åŸæœ‰
    
    Args:
        existing_choice: å·²æœ‰çš„é€‰æ‹©æ•°æ®
        new_choice: æ–°æŠ“å–çš„é€‰æ‹©æ•°æ®
    
    Returns:
        åˆå¹¶åçš„é€‰æ‹©æ•°æ®
    """
    merged = existing_choice.copy()
    
    # æè¿°ï¼šåªæœ‰æ–°æè¿°ä¸ä¸ºç©ºæ—¶æ‰è¦†ç›–
    if new_choice.get('description', '').strip():
        merged['description'] = new_choice['description']
    
    # URLï¼šåªæœ‰æ–°URLä¸ä¸ºç©ºæ—¶æ‰è¦†ç›–
    if new_choice.get('url', '').strip():
        merged['url'] = new_choice['url']
    
    # å›¾æ ‡URLï¼šåªæœ‰æ–°å›¾æ ‡URLä¸ä¸ºç©ºæ—¶æ‰è¦†ç›–
    if new_choice.get('icon_url', '').strip():
        merged['icon_url'] = new_choice['icon_url']
    
    # å›¾æ ‡è·¯å¾„ï¼šåªæœ‰æ–°å›¾æ ‡ä¸‹è½½æˆåŠŸæ—¶æ‰è¦†ç›–
    if (new_choice.get('icon', '').strip() and 
        new_choice['icon'] != "icons/placeholder.webp" and
        not new_choice['icon'].startswith('icons/placeholder')):
        merged['icon'] = new_choice['icon']
    
    # é•¿å®½æ¯”ï¼šåªæœ‰æ–°é•¿å®½æ¯”æœ‰æ•ˆæ—¶æ‰è¦†ç›–
    if new_choice.get('aspect_ratio') is not None:
        merged['aspect_ratio'] = new_choice['aspect_ratio']
    
    return merged


def extract_pool_from_html(html_content):
    """ä»HTMLä¸­æå–poolæ•°æ®ï¼ˆé€‰æ‹©çš„åŸºæœ¬ä¿¡æ¯ï¼‰"""
    choices_data = []
    try:
        # æ‰¾åˆ° "pool":[ çš„ä½ç½®
        pattern = r'\\"pool\\":\['
        match = re.search(pattern, html_content)
        
        if not match:
            return []
        
        start_pos = match.end()  # ä» [ ä¹‹åå¼€å§‹
        
        # ä½¿ç”¨æ‹¬å·è®¡æ•°æ¥æ‰¾åˆ°å®Œæ•´çš„æ•°ç»„
        bracket_count = 1  # å·²ç»æœ‰ä¸€ä¸ª [
        i = start_pos
        
        while i < len(html_content) and bracket_count > 0:
            if html_content[i] == '[':
                bracket_count += 1
            elif html_content[i] == ']':
                bracket_count -= 1
            i += 1
        
        if bracket_count == 0:
            # æ‰¾åˆ°äº†å®Œæ•´çš„æ•°ç»„
            pool_str = html_content[start_pos:i-1]  # i-1 å› ä¸ºä¸åŒ…æ‹¬æœ€åçš„ ]
            
            # åè½¬ä¹‰å¹¶è§£æ
            pool_json_str = '[' + pool_str + ']'
            pool_json_str = pool_json_str.replace('\\"', '"')
            
            try:
                pool_data = json.loads(pool_json_str)
                
                for choice_data in pool_data:
                    choice = {
                        'name': choice_data.get('title', ''),
                        'url': 'https://bazaardb.gg' + choice_data.get('url', ''),
                        'icon_url': choice_data.get('art', '')
                    }
                    choices_data.append(choice)
                    
            except json.JSONDecodeError as e:
                print(f"    âœ— JSONè§£æå¤±è´¥: {e}")
    
    except Exception as e:
        print(f"    âœ— æå–poolæ•°æ®å¤±è´¥: {e}")
    
    return choices_data


def extract_choice_descriptions_from_event_page(driver, choices):
    """ä»äº‹ä»¶è¯¦æƒ…é¡µçš„DOMä¸­æå–æ‰€æœ‰é€‰æ‹©çš„æè¿°
    
    Args:
        driver: Selenium WebDriverï¼ˆå·²ç»åœ¨äº‹ä»¶è¯¦æƒ…é¡µï¼‰
        choices: é€‰æ‹©åˆ—è¡¨ï¼ŒåŒ…å«nameå’Œurl
    
    Returns:
        dict: {choice_name: description} çš„å­—å…¸
    """
    descriptions = {}
    
    try:
        # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
        time.sleep(2)
        
        # è·å–æ‰€æœ‰h3å…ƒç´ ï¼ˆåŒ…å«é€‰æ‹©åç§°ï¼‰
        try:
            h3_elements = driver.find_elements(By.TAG_NAME, 'h3')
            
            for h3 in h3_elements:
                try:
                    # è·å–é€‰æ‹©åç§°ï¼ˆåœ¨h3çš„spanä¸­ï¼‰
                    span = h3.find_element(By.TAG_NAME, 'span')
                    choice_name = span.text.strip()
                    
                    if not choice_name:
                        continue
                    
                    # æ‰¾åˆ°h3çš„çˆ¶å®¹å™¨ï¼ˆåº”è¯¥æ˜¯é€‰æ‹©å¡ç‰‡å®¹å™¨ï¼‰
                    # å°è¯•å‘ä¸ŠæŸ¥æ‰¾åŒ…å«æè¿°çš„å®¹å™¨
                    try:
                        # æ–¹æ³•1: æŸ¥æ‰¾çˆ¶å…ƒç´ ä¸­çš„ div._bk æˆ– div._bq
                        parent = h3.find_element(By.XPATH, './ancestor::div[contains(@class, "_")]')
                        try:
                            desc_elem = parent.find_element(By.CSS_SELECTOR, 'div._bk, div._bq')
                            description = desc_elem.text.strip()
                            if description and len(description) > 5:
                                descriptions[choice_name] = description
                                continue
                        except:
                            pass
                    except:
                        pass
                    
                    # æ–¹æ³•2: æŸ¥æ‰¾h3çš„ä¸‹ä¸€ä¸ªå…„å¼Ÿå…ƒç´ ä¸­çš„æè¿°
                    try:
                        # è·å–h3çš„ä¸‹ä¸€ä¸ªå…„å¼Ÿå…ƒç´ 
                        next_sibling = h3.find_element(By.XPATH, './following-sibling::div[contains(@class, "_bk") or contains(@class, "_bq")][1]')
                        description = next_sibling.text.strip()
                        if description and len(description) > 5:
                            descriptions[choice_name] = description
                    except:
                        pass
                        
                except Exception as e:
                    continue
        
        except Exception as e:
            print(f"    âš ï¸ ä»DOMæå–æè¿°å¤±è´¥: {e}")
        
        # å¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œä½¿ç”¨HTMLæºç æå–
        if not descriptions:
            try:
                html = driver.page_source
                
                # æŸ¥æ‰¾æ‰€æœ‰h3å…ƒç´ ï¼Œç„¶åæŸ¥æ‰¾å¯¹åº”çš„æè¿°
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾h3å’Œç´§éšå…¶åçš„æè¿°
                h3_pattern = r'<h3[^>]*>.*?<span[^>]*>(.*?)</span>.*?</h3>'
                h3_matches = list(re.finditer(h3_pattern, html, re.DOTALL))
                
                for match in h3_matches:
                    choice_name = re.sub(r'<[^>]+>', '', match.group(1)).strip()
                    if not choice_name:
                        continue
                    
                    # åœ¨h3åé¢æŸ¥æ‰¾æè¿°ï¼ˆåœ¨div._bkæˆ–div._bqä¸­ï¼‰
                    search_start = match.end()
                    desc_pattern = r'<div[^>]*class="[^"]*(_bk|_bq)[^"]*"[^>]*>(.*?)</div>'
                    desc_match = re.search(desc_pattern, html[search_start:search_start+2000], re.DOTALL)
                    
                    if desc_match:
                        description = re.sub(r'<[^>]+>', '', desc_match.group(2))
                        description = description.replace('&nbsp;', ' ')
                        description = description.replace('&amp;', '&')
                        description = description.replace('&lt;', '<')
                        description = description.replace('&gt;', '>')
                        description = description.replace('&#x27;', "'")
                        description = description.strip()
                        
                        if description and len(description) > 5:
                            descriptions[choice_name] = description
            
            except Exception as e:
                print(f"    âš ï¸ ä»HTMLæºç æå–æè¿°å¤±è´¥: {e}")
    
    except Exception as e:
        print(f"    âš ï¸ æå–é€‰æ‹©æè¿°æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
    
    return descriptions


def extract_event_details(driver, event_name, detail_url, existing_event=None):
    """ä»è¯¦æƒ…é¡µæå–äº‹ä»¶ä¿¡æ¯
    
    Args:
        driver: Selenium WebDriver
        event_name: äº‹ä»¶åç§°
        detail_url: è¯¦æƒ…é¡µURL
        existing_event: å·²æœ‰çš„äº‹ä»¶æ•°æ®ï¼ˆç”¨äºæ™ºèƒ½è¦†ç›–ï¼‰
    
    Returns:
        äº‹ä»¶æ•°æ®å­—å…¸
    """
    print(f"\n  [2/3] è®¿é—®äº‹ä»¶è¯¦æƒ…é¡µ...")
    driver.get(detail_url)
    time.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½
    
    html_content = driver.page_source
    
    # ä¿å­˜HTMLåˆ°æ–‡ä»¶
    html_filename = event_name.replace('/', '_').replace('\\', '_') + '.html'
    html_filepath = HTML_DIR / html_filename
    with open(html_filepath, 'w', encoding='utf-8') as f:
        f.write(html_content)
    print(f"  âœ“ HTMLå·²ä¿å­˜åˆ°: {html_filepath}")
    
    # æ­¥éª¤1ï¼šä»scriptæ ‡ç­¾ä¸­æå–poolæ•°æ®ï¼ˆåŸºæœ¬ä¿¡æ¯ï¼‰
    print(f"\n  [3/3] æå–é€‰æ‹©ä¿¡æ¯...")
    choices = extract_pool_from_html(html_content)
    
    if not choices:
        ERROR_LOG['missing_choices'].append({
            'event': event_name,
            'url': detail_url
        })
        print(f"    âš ï¸  æœªæ‰¾åˆ°é€‰æ‹©")
        # å¦‚æœå·²æœ‰æ•°æ®ï¼Œè¿”å›å·²æœ‰æ•°æ®
        if existing_event:
            print(f"    â„¹ï¸  ä¿ç•™å·²æœ‰æ•°æ®")
            return existing_event
        return None
    
    print(f"    âœ“ æ‰¾åˆ° {len(choices)} ä¸ªé€‰æ‹©")
    
    event_data = {
        "name": event_name,
        "url": detail_url,
        "choices": []
    }
    
    # è·å–å·²æœ‰é€‰æ‹©æ•°æ®ï¼ˆç”¨äºæ™ºèƒ½è¦†ç›–ï¼‰
    existing_choices = {}
    if existing_event:
        existing_choices = {choice['name']: choice for choice in existing_event.get('choices', [])}
    
    # ä»äº‹ä»¶è¯¦æƒ…é¡µæå–æ‰€æœ‰é€‰æ‹©çš„æè¿°
    print(f"\n  æå–é€‰æ‹©æè¿°...")
    choice_descriptions = extract_choice_descriptions_from_event_page(driver, choices)
    
    # å¤„ç†æ¯ä¸ªé€‰æ‹©
    print(f"\n  ä¸‹è½½é€‰æ‹©å›¾æ ‡...")
    for idx, choice in enumerate(choices, 1):
        choice_name = choice['name']
        choice_url = choice['url']
        print(f"    [{idx}/{len(choices)}] {choice_name}")
        
        # ä»æå–çš„æè¿°å­—å…¸ä¸­è·å–æè¿°
        description = choice_descriptions.get(choice_name, "")
        if description:
            print(f"        âœ“ æè¿°: {description[:80]}...")
        else:
            print(f"        âš ï¸  æœªæ‰¾åˆ°æè¿°")
            ERROR_LOG['failed_descriptions'].append({
                'event': event_name,
                'choice': choice_name
            })
        
        # ä¸‹è½½å›¾æ ‡å¹¶è·å–é•¿å®½æ¯”
        icon_path, aspect_ratio = download_icon(choice['icon_url'], event_name, choice_name)
        
        # æ™ºèƒ½è¦†ç›–é€»è¾‘
        choice_data = {
            "name": choice_name,
            "url": choice['url'],
            "icon": icon_path,
            "icon_url": choice['icon_url'],
            "description": description,
            "aspect_ratio": aspect_ratio
        }
        
        # å¦‚æœå·²æœ‰æ•°æ®ï¼Œè¿›è¡Œæ™ºèƒ½åˆå¹¶
        if choice_name in existing_choices:
            existing_choice = existing_choices[choice_name]
            choice_data = smart_merge_choice_data(existing_choice, choice_data)
            print(f"      ğŸ”„ æ™ºèƒ½åˆå¹¶å·²æœ‰æ•°æ®")
        
        event_data["choices"].append(choice_data)
    
    return event_data


def save_events_to_json(events_list, output_file):
    """ä¿å­˜äº‹ä»¶æ•°æ®åˆ°JSONæ–‡ä»¶"""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(events_list, f, ensure_ascii=False, indent=2)


def save_error_log():
    """ä¿å­˜é”™è¯¯æ—¥å¿—åˆ°æ–‡ä»¶"""
    import datetime
    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = LOGS_DIR / f'error_log_{timestamp}.json'
    
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(ERROR_LOG, f, ensure_ascii=False, indent=2)
    
    return log_file


def load_existing_events(output_file):
    """åŠ è½½å·²å¤„ç†çš„äº‹ä»¶æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
    if output_file.exists():
        try:
            with open(output_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    return []


def get_event_detail_url(driver, event_name, max_retries=3):
    """ä»æœç´¢é¡µé¢è·å–äº‹ä»¶è¯¦æƒ…URL
    
    Args:
        driver: Selenium WebDriver
        event_name: äº‹ä»¶åç§°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        äº‹ä»¶è¯¦æƒ…é¡µURLæˆ–None
    """
    for attempt in range(max_retries):
        try:
            search_url = f"https://bazaardb.gg/search?c=events&q={event_name.replace(' ', '+')}"
            driver.get(search_url)
            time.sleep(3)
            
            # ä½¿ç”¨JavaScriptæŸ¥æ‰¾é“¾æ¥
            script = """
            const links = Array.from(document.querySelectorAll('a[href*="/card/"]'));
            if (links.length > 0) {
                return links[0].href;
            }
            return null;
            """
            
            url = driver.execute_script(script)
            if url:
                return url
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´å†è¯•
            if attempt < max_retries - 1:
                time.sleep(2)
                continue
            
            ERROR_LOG['missing_detail_urls'].append(event_name)
            return None
            
        except Exception as e:
            error_msg = str(e)
            # å¦‚æœæ˜¯ç½‘ç»œé”™è¯¯ï¼Œé‡è¯•
            if 'ERR_CONNECTION' in error_msg or 'timeout' in error_msg.lower():
                if attempt < max_retries - 1:
                    print(f"        ç½‘ç»œé”™è¯¯ï¼Œé‡è¯• {attempt + 1}/{max_retries}...")
                    time.sleep(5)
                    continue
            
            # å…¶ä»–é”™è¯¯æˆ–æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
            if attempt == max_retries - 1:
                ERROR_LOG['exceptions'].append({
                    'event': event_name,
                    'stage': 'get_detail_url',
                    'error': error_msg
                })
            return None
    
    return None


def main(test_limit=None):
    """ä¸»å‡½æ•°
    
    Args:
        test_limit: æµ‹è¯•æ¨¡å¼ä¸‹é™åˆ¶å¤„ç†çš„äº‹ä»¶æ•°é‡ï¼ˆNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰äº‹ä»¶ï¼‰
    """
    print("=" * 80)
    print("äº‹ä»¶çˆ¬è™« - å®Œæ•´ç‰ˆ")
    if test_limit:
        print(f"æµ‹è¯•æ¨¡å¼: åªå¤„ç†å‰ {test_limit} ä¸ªäº‹ä»¶")
    print("=" * 80)
    
    # åŠ è½½äº‹ä»¶åç§°
    event_names = load_event_names(EVENTS_FILE)
    if not event_names:
        print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°äº‹ä»¶åç§°")
        return
    
    # æµ‹è¯•æ¨¡å¼ä¸‹é™åˆ¶äº‹ä»¶æ•°é‡
    if test_limit:
        event_names = event_names[:test_limit]
    
    print(f"\næ€»å…± {len(event_names)} ä¸ªäº‹ä»¶éœ€è¦å¤„ç†")
    
    # åŠ è½½å·²å¤„ç†çš„äº‹ä»¶
    output_file = OUTPUT_DIR / 'events.json'
    existing_events = load_existing_events(output_file)
    processed_names = {event['name'] for event in existing_events}
    
    print(f"å·²å¤„ç† {len(processed_names)} ä¸ªäº‹ä»¶")
    
    # è®¾ç½®é©±åŠ¨
    driver = setup_driver()
    
    try:
        events_data = existing_events.copy()
        
        for idx, event_name in enumerate(event_names, 1):
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­¤äº‹ä»¶çš„æ•°æ®
            existing_event = None
            for existing in existing_events:
                if existing['name'] == event_name:
                    existing_event = existing
                    break
            
            if existing_event:
                print(f"\n[{idx}/{len(event_names)}] {event_name} - æ›´æ–°å·²æœ‰æ•°æ®")
            else:
                print(f"\n[{idx}/{len(event_names)}] {event_name} - æ–°äº‹ä»¶")
            
            print(f"\n{'=' * 80}")
            print(f"[{idx}/{len(event_names)}] å¤„ç†äº‹ä»¶: {event_name}")
            print('=' * 80)
            
            try:
                # è·å–è¯¦æƒ…URL
                print(f"  [1/3] æœç´¢äº‹ä»¶è¯¦æƒ…é¡µ...")
                detail_url = get_event_detail_url(driver, event_name)
                
                if not detail_url:
                    print(f"  âš ï¸  æœªæ‰¾åˆ°è¯¦æƒ…é¡µURL")
                    continue
                
                print(f"  âœ“ è¯¦æƒ…é¡µ: {detail_url}")
                
                # æå–äº‹ä»¶è¯¦æƒ…
                event_data = extract_event_details(driver, event_name, detail_url, existing_event)
                
                if event_data:
                    if existing_event:
                        # æ›´æ–°å·²æœ‰äº‹ä»¶æ•°æ®
                        events_data = [e for e in events_data if e['name'] != event_name]
                    events_data.append(event_data)
                    processed_names.add(event_name)
                    
                    # å¢é‡ä¿å­˜
                    save_events_to_json(events_data, output_file)
                    print(f"\n  âœ“ äº‹ä»¶æ•°æ®å·²ä¿å­˜")
                
            except KeyboardInterrupt:
                print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜å½“å‰è¿›åº¦...")
                save_events_to_json(events_data, output_file)
                raise
            
            except Exception as e:
                print(f"\n  âœ— å¤„ç†å¤±è´¥: {e}")
                ERROR_LOG['failed_events'].append({
                    'event': event_name,
                    'error': str(e)
                })
                continue
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        save_events_to_json(events_data, output_file)
        
        # ä¿å­˜é”™è¯¯æ—¥å¿—
        log_file = save_error_log()
        
        print(f"\n{'=' * 80}")
        print("çˆ¬å–å®Œæˆ!")
        print('=' * 80)
        print(f"âœ“ æˆåŠŸå¤„ç† {len(events_data)} ä¸ªäº‹ä»¶")
        print(f"âœ“ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        print(f"âœ“ é”™è¯¯æ—¥å¿—: {log_file}")
        
        # æ‰“å°è¯¦ç»†çš„é”™è¯¯æŠ¥å‘Š
        print(f"\n{'=' * 80}")
        print("é”™è¯¯ç»Ÿè®¡:")
        print('=' * 80)
        print(f"  - å¤±è´¥çš„äº‹ä»¶: {len(ERROR_LOG['failed_events'])}")
        print(f"  - ç¼ºå°‘è¯¦æƒ…URL: {len(ERROR_LOG['missing_detail_urls'])}")
        print(f"  - ç¼ºå°‘é€‰æ‹©: {len(ERROR_LOG['missing_choices'])}")
        print(f"  - å›¾æ ‡ä¸‹è½½å¤±è´¥: {len(ERROR_LOG['failed_choice_downloads'])}")
        print(f"  - æè¿°æå–å¤±è´¥: {len(ERROR_LOG['failed_descriptions'])}")
        print(f"  - å¼‚å¸¸: {len(ERROR_LOG['exceptions'])}")
        
        # æ‰“å°è¯¦ç»†åˆ—è¡¨
        if ERROR_LOG['missing_detail_urls']:
            print(f"\nç¼ºå°‘è¯¦æƒ…URLçš„äº‹ä»¶:")
            for event in ERROR_LOG['missing_detail_urls']:
                print(f"  - {event}")
        
        if ERROR_LOG['missing_choices']:
            print(f"\nç¼ºå°‘é€‰æ‹©çš„äº‹ä»¶:")
            for item in ERROR_LOG['missing_choices']:
                print(f"  - {item['event']}: {item['url']}")
        
        if ERROR_LOG['failed_descriptions']:
            print(f"\nç¼ºå°‘æè¿°çš„é€‰æ‹©:")
            for item in ERROR_LOG['failed_descriptions']:
                print(f"  - {item['event']} -> {item['choice']}")
        
        if ERROR_LOG['failed_choice_downloads']:
            print(f"\nå›¾æ ‡ä¸‹è½½å¤±è´¥çš„é€‰æ‹©:")
            for item in ERROR_LOG['failed_choice_downloads'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  - {item.get('event', 'N/A')} -> {item.get('choice', 'N/A')}")
            if len(ERROR_LOG['failed_choice_downloads']) > 10:
                print(f"  ... å’Œå…¶ä»– {len(ERROR_LOG['failed_choice_downloads']) - 10} ä¸ª")
        
        if ERROR_LOG['failed_events']:
            print(f"\nå®Œå…¨å¤±è´¥çš„äº‹ä»¶:")
            for item in ERROR_LOG['failed_events']:
                print(f"  - {item['event']}: {item.get('error', 'Unknown error')}")
        
    except KeyboardInterrupt:
        print("\n\nçˆ¬å–è¢«ç”¨æˆ·ä¸­æ–­")
        log_file = save_error_log()
        print(f"âœ“ å½“å‰è¿›åº¦å·²ä¿å­˜åˆ°: {output_file}")
        print(f"âœ“ é”™è¯¯æ—¥å¿—: {log_file}")
        
        # æ‰“å°é”™è¯¯æŠ¥å‘Š
        print(f"\n{'=' * 80}")
        print("å½“å‰é”™è¯¯ç»Ÿè®¡:")
        print('=' * 80)
        print(f"  - å·²å¤„ç†: {len(events_data)} ä¸ªäº‹ä»¶")
        print(f"  - ç¼ºå°‘è¯¦æƒ…URL: {len(ERROR_LOG['missing_detail_urls'])} ä¸ª")
        print(f"  - ç¼ºå°‘é€‰æ‹©: {len(ERROR_LOG['missing_choices'])} ä¸ª")
        print(f"  - æè¿°æå–å¤±è´¥: {len(ERROR_LOG['failed_descriptions'])} ä¸ª")
        print(f"  - å›¾æ ‡ä¸‹è½½å¤±è´¥: {len(ERROR_LOG['failed_choice_downloads'])} ä¸ª")
        
        if ERROR_LOG['missing_detail_urls']:
            print(f"\nç¼ºå°‘è¯¦æƒ…URLçš„äº‹ä»¶:")
            for event in ERROR_LOG['missing_detail_urls']:
                print(f"  - {event}")
    
    finally:
        driver.quit()
        print("\næµè§ˆå™¨å·²å…³é—­")


if __name__ == "__main__":
    import sys
    # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰3ä¸ªäº‹ä»¶
    if '--test' in sys.argv or '-t' in sys.argv:
        print("=" * 80)
        print("æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰3ä¸ªäº‹ä»¶")
        print("=" * 80)
        main(test_limit=3)
    else:
        main()

